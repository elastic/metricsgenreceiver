receivers:
  metricsgen:
    start_now_minus: 1h
    interval: 5s
    interval_jitter_std_dev: 1ms
    real_time: false
    exit_after_end: true
    seed: 123
    scenarios:
#    - path: builtin/tsbs-devops
#      scale: 100
    - path: builtin/hostmetrics
      scale: 100
#    - path: builtin/kubeletstats-node
#      scale: 10
#    - path: builtin/kubeletstats-pod
#      scale: 1000
#    - path: builtin/elasticapm-service-metrics
#      scale: 100
##      temporality_override: cumulative
#    - path: builtin/elasticapm-span-destination-metrics
#      scale: 100
##      temporality_override: cumulative
#      template_vars:
#        destinations: 10
#    - path: builtin/elasticapm-transaction-metrics
#      scale: 1000
##      temporality_override: cumulative
#      template_vars:
#        services: 100
#        transactions: 50
#    - path: builtin/simple
#      scale: 10000
#      template_vars:
#        counter: 1
#        gauge_pct: 0
#        gauge_int: 0

processors:
  batch:

extensions:
  pprof:

exporters:
  debug:
    verbosity: detailed
  file:
    path: ./file-exporter/metrics-generated.json
  nop:
  otlphttp/victoriametrics:
    compression: gzip
    encoding: proto
    endpoint: http://localhost:8428/opentelemetry
    sending_queue:
      enabled: true
      block_on_overflow: true
      queue_size: 10
      num_consumers: 10
  prometheusremotewrite/victoriametrics:
    endpoint: "http://localhost:8428/api/v1/write"
    resource_to_telemetry_conversion:
      enabled: true
    remote_write_queue:
      enabled: false
  elasticsearch:
    endpoint: "http://localhost:9200"
    mapping:
      mode: otel
    metrics_dynamic_index:
      enabled: true
    num_workers: 10

service:
#  extensions: [pprof]
  pipelines:
    metrics:
      receivers: [metricsgen]
      processors: [batch]
#      exporters: [nop]
#      exporters: [elasticsearch] # do not use with batch processor. ES exporter is doing batching internally.
      exporters: [otlphttp/victoriametrics] # only use with batch processor
